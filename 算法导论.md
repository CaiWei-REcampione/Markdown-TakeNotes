# 算法

## 输入与输出

待计算问题的任一实例,都需要以某种方式交给对应的算法,对所求解问题特定实例的这种描述统称为输入(input)

## 基本操作、确定性与可行性

所谓确定性和可行性是指,算法应可描述为由若干语义明确的基本操作组成的指令序列,且每一基本操作在对应的计算模型中均可兑现

## 有穷性与正确性

不难理解,任意算法都应在执行有限次基本操作之后终止并给出输出,此即所谓算法的有穷性(finiteness) .进一步地,算法不仅应该迟早会终止,而且所给的输出还应该能够符合由问题本身在事先确定的条件,此即所谓算法的正确性(correctness)

> 证明算法有穷性和正确性的一个重要技巧,就是从适当的角度审视整个计算过程,并找出其所具有的某种不变性和单调性.其中的单调性通常是指问题的有效规模会随着算法的推进不断递减.不变性则不仅应在算法初始状态下自然满足,而且应与最终的正确性相呼应-当问题的有效规模缩减到0时,不变性应随即等价于正确性

## 退化与鲁棒性

同一问题往往不限于一种算法,而同一算法也常常会有多种实现方式,因此除了以上必须具备的基本属性,在应用环境中还需从实用的角度对不同算法及其不同版本做更为细致考量和取舍.这些细致的要求尽管应纳入软件工程的范畴,但也不失为成熟算法的重要标志.比如其中之一就是,除一般性情况外,实用的算法还应能够处理各种极端的输入实例.算法所谓的鲁棒性(robustness) ,就是要求能够尽可能充分地应对此类情况

## 重用性

从实用角度评判不同算法及其不同实现方式时,可采用的另一标准是:算法的总体框架能否便捷地推广至其它场合.算法模式可推广并适用于不同类型基本元素的这种特性,即是重用性的一种典型形式

# 算法效率

## 可计算性

程序设计语言的目的,在于学会如何编写合法(即合乎特定程序语言的语法)的程序,从而保证编写的程序或者能够经过编译和链接生成执行代码,或者能够由解释器解释执行.然而从通过计算有效解决实际问题的角度来看,这只是第一个层次,仅仅做到语法正确还远远不够.很遗憾,算法所应具备的更多基本性质,合法的程序并非总是自然具备

## 难解性

实际上我们不仅需要确定,算法对任何输入都能够在有穷次操作之后终止,而且更加关注该过程所需的时间.很遗憾,很多算法即便满足有穷性,但在终止之前所花费的时间成本却太高

## 计算效率

首先需要确立一种尺度,用以从==时间和空间==等方面度量算法的计算成本,进而依此尺度对不同算法进行比较和评判.当然,更重要的是研究和归纳算法设计与实现过程中的一般性规律与技巧,以编写出效率更高、能够处理更大规模数据的程序

## 数据结构

无论是算法的初始输入、中间结果还是最终输出,在计算机中都可以数据的形式表示.对于数据的存储、组织、转移及变换等操作,不同计算模型和平台环境所支持的具体形式不尽相同,其执行效率将直接影响和决定算法的整体效率.数据结构这一学科正是以“数据”这"一信息的表现形式为研究对象,旨在建立支持高效算法的数据信息处理策略、技巧与方法.要做到根据实际应用需求自如地设计、实现和选用适当的数据结构,必须首先对算法设计的技巧以及相应数据结构的特性了然于心

## 复杂度度量

### 时间复杂度

即使是同一算法,对于不同的输入所需的运行时间并不相同.为针对运行时间建立起一种可行、可信的评估标准,我们不得不首先考虑其中最为关键的因素.其中,问题实例的规模往往是决定计算成本的主要因素.一般地,问题规模越接近,相应的计算成本也越接近;而随着问题规模的扩大,计算成本通常也呈上升趋势

### 渐进复杂度

对于同一问题的两个算法A和B,通过比较其时间复杂度$T_A(n)$和$T_B(n)$,即可评价二者对于同一输入规模n的计算效率高低.然而,藉此还不足以就其性能优劣做出总体性的评判,比如对于某些问题,一些算法更适用于小规模输入,而另一些则相反.幸运的是,在评价算法运行效率时,我们往往可以忽略其处理小规模问题时的能力差异,转而关注其在处理更大规模问题时的表现.其中的原因不难理解,小规模问题所需的处理时间本来就相对更少,故此时不同算法的实际效率差异并不明显;而在处理更大规模的问题时,效率的些许差异都将对实际执行效果产生巨大的影响.这种着眼长远、更为注重时间复杂度的总体变化趋势和增长速度的策略与方法,即所谓的渐进分析(asymptotic analysis) 

#### 大$\sigma$记号

同样地出于保守的估计,我们首先关注T(n)的渐进上界.为此可引入所谓“大$\sigma$记号”(big-0 notation) .具体地,若存在正的常数c和函数f(n),使得对任何n >> 2都有
$$
T(n) \leq c.f(n)
$$
则可认为在n足够大之后, f(n)给出了T(n)增长速度的一个渐进上界.此时,记之为:
$$
T(n) =\sigma(f(n))
$$
由这一定义,可导出大0记号的以下性质:

1. 对于任一常数c > 0,有$\sigma(f(n)) = \sigma(c\cdot f(n))$
2. 对于任意常数a > b > 0,有$\sigma(n^a+n^b) = \sigma(n^a)$

前一性质意味着,在大$\sigma$记号的意义下,函数各项正的常系数可以忽略并等同于1.后一性质则意味着,多项式中的低次项均可忽略,只需保留最高次项.可以看出,大$\sigma$记号的这些性质的确体现了对函数总体渐进增长趋势的关注和刻画

#### 环境差异

在实际环境中直接测得的执行时间T(n),虽不失为衡量算法性能的一种指标,但作为评判不同算法性能优劣的标准,其可信度值得推敲.事实上,即便是同一算法、同一输入,在不同的硬件平台上、不同的操作系统中甚至不同的时间,所需要的计算时间都不尽相同.因此,有必要按照超脱于具体硬件平台和软件环境的某一客观标准,来度量算法的时间复杂度,并进而评价不同算法的效率差异

#### 基本操作

一种自然且可行的解决办法是,将时间复杂度理解为算法中各条指令的执行时间之和.在图灵机(Turing Machine, TM)和随机存储机(Random Access Machine, RAM)等计算模型中,指令语句均可分解为若干次基本操作,比如算术运算、比较、分支、子程序调用与返回等;而在大多数实际的计算环境中,每一次这类基本操作都可在常数时间内完成.如此,不妨将T(n)定义为算法所执行基本操作的总次数.也就是说, T(n)决定于组成算法的所有语句各自的执行次数,以及其中所含基本操作的数目

#### 最坏、最好与平均情况

![image-20210704233544642](%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA.assets/image-20210704233544642.png)

以大$\sigma$记号形式表示的时间复杂度,实质上是对算法执行时间的一种保守估计-对于规模为n的任意输入,算法的运行时间都不会超过$\sigma(f(n))$.的确需要这么长计算时间的输入实例,称作最坏实例或最坏情况(worst case)

需强调的是,这种保守估计并不排斥更好情况甚至最好情况(best case)的存在和出现.当然,有时也需要考查所谓的平均情况(average case) ,也就是按照某种约定的概率分布,将规模为n的所有输入对应的计算时间加权平均.比较而言, “最坏情况复杂度”是人们最为关注且使用最多的,在一些特殊的场合甚至成为唯一的指标

#### 大$\Omega$记号

为了对算法的复杂度最好情况做出估计,需要借助另一个记号.如果存在正的常数c和函数(n),使得对于任何n >> 2都有
$$
T(n) \geq c\cdot g(n)
$$
就可以认为,在n足够大之后, g(n)给出了T(n)的一个渐进下界.此时,我们记之为:
$$
T(n) =\Omega(g(n))
$$
这里的$\Omega$称作“大$\Omega$记号” (big-omega notation) .与大$\sigma$号恰好相反,大$\Omega$记号是对算法执行效率的乐观估计-对于规模为n的任意输入,算法的运行时间都不低于$\Omega(g(n))$

#### 大$\Theta$记号

借助大$\sigma$记号、大$\Omega$记号,可以对算法的时间复杂度作出定量的界定,亦即,从渐进的趋势看, T(n)介于$\Omega(g(n))$与$\sigma(f(n))$之间.若恰巧出现g(n) =f(n)的情况,则可以使用另一记号来表示

如果存在正的常数$c1 < c2$和函数h(n),使得对于任何n >> 2都有
$$
c_1\cdot h(n) \leq T(n) \leq c_2\cdot h(n)
$$
就可以认为在n足够大之后, h(n)给出了T(n)的一个确界.此时,我们记之为:
$$
T(n) =\Theta(h(n))
$$
这里的$\Theta$称作“大$\Theta$记号” (big-theta notation) ,它是对算法复杂度的准确估计.对于规模为n的任何输入,算法的运行时间T(n)都与$\Theta(h(n))$同阶

### 空间复杂度

除了执行时间的长短,算法所需存储空间的多少也是衡量其性能的一个重要方面,此即所谓的空间复杂度(space complexity) 。实际上,以上针对时间复杂度所引入的几种渐进记号,也适用于对空间复杂度的度量,其原理及方法基本相同,不再赘述

需要注意的是,为了更为客观地评价算法性能的优劣,除非特别申明,空间复杂度通常并不计入原始输入本身所占用的空间-对于同一问题,这一指标对任何算法都是相同的。反之,其它(如转储、中转、索引、映射、缓冲等)各个方面所消耗的空间,则都应计入。

另外,很多时候我们都是更多地甚至仅仅关注于算法的时间复杂度,而不必对空间复杂度做专门的考查。这种简便评测方式的依据,来自于以下事实:==就渐进复杂度的意义而言,在任一算法的任何一次运行过程中所消耗的存储空间,都不会多于其间所执行基本操作的累计次数==

实际上根据定义,每次基本操作所涉及的存储空间,都不会超过常数规模;纵然每次基本操作所占用或访问的存储空间都是新开辟的,整个算法所需的空间总量,也不过与基本操作的次数同阶。==从这个意义上说,时间复杂度本身就是空间复杂度的一个天然的上界==

当然,对空间复杂度的分析也有其自身的意义,尤其在对空间效率非常在乎的应用场合中,或当问题的输入规模极为庞大时,由时间复杂度所确立的平凡上界已经难以令人满意。这类情况下,人们将更为精细地考查不同算法的空间效率,并尽力在此方面不断优化

## 复杂度分析

